import os
import glob
import logging
import subprocess
import pandas as pd
from config import PATH_INPUT, PATH_OUTPUT, LOG_FILE
from utils import limpiar_texto, reparar_encoding, obtener_metricas_y_duplicados
from validaciones import validate_data
from check_referencial import verificar_integridad

# Configuraci√≥n centralizada de Logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def ejecutar_pipeline():
    logging.info("üöÄ --- INICIANDO PIPELINE---")

    # Identifiacion de archivos a procesar 
    archivos = glob.glob(os.path.join(PATH_INPUT, "*.csv"))
    if not archivos:
        logging.error(f"‚ùå No se encontraron archivos en {PATH_INPUT}")
        return

    # Procesamiento e ingesta de cada archivo
    for ruta_archivo in archivos:
        nombre_archivo = os.path.basename(ruta_archivo)
        logging.info(f"üìÑ Procesando: {nombre_archivo}")

        try:
            # Lectura del CSV con manejo de encoding y delimitadores variados
            df = pd.read_csv(ruta_archivo, encoding='utf-8-sig', sep=None, engine='python')
            
            # Limpieza llamando a Utils 
            df = df.map(reparar_encoding)
            df.columns = [limpiar_texto(col) for col in df.columns]
            
            
            # Si validate_data retorna False, abortamos el pipeline
            if not validate_data(df, nombre_archivo):
                logging.critical(f"üõë Error de validaci√≥n cr√≠tica en {nombre_archivo}. ABORTANDO PIPELINE.")
                return 

            # Guardado de archivo procesado
            nombre_limpio = limpiar_texto(nombre_archivo.replace(".csv", "")) + "_limpio.csv"
            df.to_csv(os.path.join(PATH_OUTPUT, nombre_limpio), index=False)
            logging.info(f"‚úÖ Archivo '{nombre_limpio}' listo para DuckDB.")

        except Exception as e:
            logging.error(f"‚ùå Error inesperado al procesar {nombre_archivo}: {e}")
            return

    # Carga a duckdb y creaci√≥n del modelo estrella
    logging.info("‚è≥ Iniciando carga y transformaci√≥n en DuckDB...")
    try:
        script_carga = os.path.join(os.path.dirname(__file__), "cargar_duckdb.py")
        subprocess.run(['python3', script_carga], check=True)
        logging.info("‚úî Carga y Modelo Estrella completados.")
    except subprocess.CalledProcessError:
        logging.error("‚ùå Fall√≥ la ejecuci√≥n de cargar_duckdb.py")
        return

    # chequeo de integridad referencial
    if verificar_integridad():
        logging.info("üõ°Ô∏è Integridad referencial verificada con √©xito.")
        logging.info("üèÅ --- PIPELINE FINALIZADO EXITOSAMENTE ---")
    else:
        logging.error("‚ùå El pipeline termin√≥ pero se detectaron inconsistencias en la DB.")

if __name__ == "__main__":
    ejecutar_pipeline()